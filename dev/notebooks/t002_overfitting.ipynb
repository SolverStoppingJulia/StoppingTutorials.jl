{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 2: The overfitting problem (handle unrelated stopping criteria)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, we present the use of Stopping to specify an \"unrelated\"\n",
    "stopping criterion. A typical example is the so-called case of \"overfitting\",\n",
    "where the optimization process is actually designed to approximate another problem."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using ADNLPModels, LinearAlgebra, NLPModels, Plots, Printf, Random, Stopping"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, we will use the classical steepest descent method with an Armijo line-search."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Stopping.armijo\n",
    "function armijo(xk, dk, fk, slope, f)\n",
    "  t = 1.0\n",
    "  fk_new = f(xk + dk)\n",
    "  while f(xk + t * dk) > fk + 1.0e-4 * t * slope\n",
    "    t /= 1.5\n",
    "    fk_new = f(xk + t * dk)\n",
    "  end\n",
    "  return t, fk_new\n",
    "end\n",
    "\n",
    "function steepest_descent(stp :: NLPStopping)\n",
    "\n",
    "  xk = stp.current_state.x\n",
    "  fk, gk = objgrad(stp.pb, xk)\n",
    "\n",
    "  OK = update_and_start!(stp, fx = fk, gx = gk)\n",
    "\n",
    "  @printf \"%2s %9s %7s %7s %7s\\n\" \"k\" \"fk\" \"||∇f(x)||\" \"t\" \"λ\"\n",
    "  @printf \"%2d %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score)\n",
    "  while !OK\n",
    "    dk = - gk\n",
    "    slope = dot(dk, gk)\n",
    "    t, fk = armijo(xk, dk, fk, slope, x->obj(stp.pb, x))\n",
    "    xk += t * dk\n",
    "    fk, gk = objgrad(stp.pb, xk)\n",
    "\n",
    "    OK = update_and_stop!(stp, x = xk, fx = fk, gx = gk)\n",
    "\n",
    "    @printf \"%2d %9.2e %7.1e %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score) t slope\n",
    "  end\n",
    "  return stp\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also generate randomly some data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(1234)\n",
    "m, n = 50, 10\n",
    "A  = rand(m, n)\n",
    "b  = A * ones(n)\n",
    "D  = vcat(A, A) + vcat(zeros(m,n), rand(m,n))\n",
    "Db = vcat(b, b)\n",
    "rperm = shuffle(1:2m)\n",
    "Dr = D[rperm,:]\n",
    "Dbr = Db[rperm,:]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We initialize two different problems evaluating respectively a training set, and a test set."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f(x, A, b, λ) = norm(A * x - b)^2 + λ * norm(x)^2\n",
    "train_pb = ADNLPModel(x -> f(x, Dr[1:m,:], Dbr[1:m], 1e-2), zeros(n))\n",
    "test_pb = ADNLPModel(x -> f(x, Dr[m+1:2m,:], Dbr[m+1:2m], 0.0), zeros(n))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial, the motivation is to use the solver on the `test_pb`, and track the efficiency of the computed solution on the `train_pb`.\n",
    "We specialize the stopping structure to store the objective function of both problems in the `stopping_user_struct`, and evaluate them in the `stp.meta.user_check_func!`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_check(stp, b) = begin\n",
    "  stp.stopping_user_struct[:test_obj][stp.meta.nb_of_stop+1] = obj(stp.stopping_user_struct[:test], stp.current_state.x)\n",
    "  stp.stopping_user_struct[:train_obj][stp.meta.nb_of_stop+1] = obj(stp.pb, stp.current_state.x)\n",
    "end\n",
    "train_obj = NaN * ones(101)\n",
    "test_obj  = NaN * ones(101)\n",
    "train_stp = NLPStopping(train_pb, user_struct = Dict(:test => test_pb, :train_obj => train_obj, :test_obj => test_obj), user_check_func! = train_check, max_iter = 100)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now run the steepest descent algorithm with the `train_stp` stopping."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "steepest_descent(train_stp)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the following plot in logarithmic scale, we can see that after a number of iterations, the progress made by the solver are no longer improving the other problem."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "#hcat(log.(train_stp.stopping_user_struct[:train_obj]), log.(train_stp.stopping_user_struct[:test_obj]))\n",
    "plot(log.(train_stp.stopping_user_struct[:train_obj]), label=[\"train obj\"])\n",
    "plot!(log.(train_stp.stopping_user_struct[:test_obj]), label=[\"test obj\"], title=\"overfitting\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](../assets/overfitting/overfitting.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To overcome this issue, one possibility is to stop the solver when the second is no longer being minimized. The only modification is to set the entry `meta.stopbyuser` to `true`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_check_opt(stp, b) = begin\n",
    "  k = stp.meta.nb_of_stop\n",
    "  stp.stopping_user_struct[:test_obj][k+1] = obj(stp.stopping_user_struct[:test], stp.current_state.x)\n",
    "  stp.stopping_user_struct[:train_obj][k+1] = obj(stp.pb, stp.current_state.x)\n",
    "  diff = k!=0 && stp.stopping_user_struct[:test_obj][k+1] - stp.stopping_user_struct[:train_obj][k+1] > 10\n",
    "  inc  = k!=0 && stp.stopping_user_struct[:test_obj][k+1] > stp.stopping_user_struct[:test_obj][k]\n",
    "  if diff && inc\n",
    "    stp.meta.stopbyuser = true\n",
    "  end\n",
    "end\n",
    "train_stp.meta.user_check_func! = train_check_opt\n",
    "reset!(train_stp.pb)\n",
    "reinit!(train_stp, rstate=true, x = zeros(10))\n",
    "steepest_descent(train_stp)\n",
    "\n",
    "nb_iter = train_stp.meta.nb_of_stop\n",
    "hcat(log.(train_stp.stopping_user_struct[:train_obj][1:nb_iter+1]), log.(train_stp.stopping_user_struct[:test_obj][1:nb_iter+1]))\n",
    "plot(log.(train_stp.stopping_user_struct[:train_obj][1:nb_iter+1]), label=[\"train obj\"])\n",
    "plot!(log.(train_stp.stopping_user_struct[:test_obj][1:nb_iter+1]), label=[\"test obj\"], title=\"overfitting\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](../assets/overfitting/overfitting_cut.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.6"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.6",
   "language": "julia"
  }
 },
 "nbformat": 4
}
