{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 5: Benchmark solvers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Benchmark"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial follows closely the tutorial [OptimizationProblems.jl](https://juliasmoothoptimizers.github.io/OptimizationProblems.jl/dev/benchmark/).\n",
    "We show how to use [SolverBenchmark.jl](https://juliasmoothoptimizers.github.io/SolverBenchmark.jl) to benchmark solvers that take a NLPStopping as input."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra, NLPModels, Stopping\n",
    "using JSOSolvers, StoppingInterface\n",
    "using DataFrames, Printf, SolverBenchmark\n",
    "using ADNLPModels, OptimizationProblems"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We select the problems from [OptimizationProblems.jl](https://juliasmoothoptimizers.github.io/OptimizationProblems.jl) that are unconstrained and scalable."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = OptimizationProblems.meta\n",
    "names_pb_vars = df[(df.variable_nvar .== true) .& (df.ncon .== 0), :name]\n",
    "\n",
    "ad_problems = (\n",
    "  OptimizationProblems.ADNLPProblems.eval(Symbol(problem))(n = 31) for problem ∈ names_pb_vars\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we prepare the solvers we will benchmark.\n",
    "Here, we use [JSOSolvers.jl](https://github.com/JuliaSmoothOptimizers/JSOSolvers.jl) that are made Stopping-compatible using [StoppingInterface.jl](https://github.com/SolverStoppingJulia/StoppingInterface.jl)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "solvers = Dict(\n",
    "  :lbfgs => model -> stopping_to_stats(StoppingInterface.lbfgs(NLPStopping(model); mem=5, atol=1e-5, rtol=0.0, max_time = 5.)),\n",
    "  :trunk => model -> stopping_to_stats(StoppingInterface.trunk(NLPStopping(model); atol=1e-5, rtol=0.0, max_time = 5.)),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The main function used from [SolverBenchmark.jl](https://juliasmoothoptimizers.github.io/SolverBenchmark.jl)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "stats = bmark_solvers(\n",
    "  solvers, ad_problems\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output of `bmark_solvers` can then be analyzed for the results as a table"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "cols = [:id, :name, :nvar, :objective, :dual_feas, :neval_obj, :neval_grad, :neval_hess, :iter, :elapsed_time, :status]\n",
    "header = Dict(\n",
    "  :nvar => \"n\",\n",
    "  :objective => \"f(x)\",\n",
    "  :dual_feas => \"‖∇f(x)‖\",\n",
    "  :neval_obj => \"# f\",\n",
    "  :neval_grad => \"# ∇f\",\n",
    "  :neval_hess => \"# ∇²f\",\n",
    "  :elapsed_time => \"t\",\n",
    ")\n",
    "\n",
    "for solver ∈ keys(solvers)\n",
    "  pretty_stats(stats[solver][!, cols], hdr_override=header)\n",
    "end\n",
    "\n",
    "first_order(df) = df.status .== :first_order\n",
    "unbounded(df) = df.status .== :unbounded\n",
    "solved(df) = first_order(df) .| unbounded(df)\n",
    "costnames = [\"time\", \"obj + grad + hess\"]\n",
    "costs = [\n",
    "  df -> .!solved(df) .* Inf .+ df.elapsed_time,\n",
    "  df -> .!solved(df) .* Inf .+ df.neval_obj .+ df.neval_grad .+ df.neval_hess,\n",
    "]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "or as a performance profile"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "gr()\n",
    "\n",
    "profile_solvers(stats, costs, costnames)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
